#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLæ…¢æŸ¥è¯¢æ—¥å¿—è§£æå™¨ - ç²¾ç®€ç‰ˆ
åŠŸèƒ½åŒ…æ‹¬ï¼šSQLæ ¼å¼åŒ–ã€å®Œæ•´å­˜å‚¨ã€ç”¨æˆ·åæ˜ å°„ã€æ—¶é—´ä¼˜åŒ–ã€ISOæ—¶é—´æˆ³æ”¯æŒ
"""

import os
import re
import hashlib
import pymysql
from datetime import datetime, timedelta
import argparse

class SlowLogParser:
    def __init__(self, min_query_time=5.0):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.min_query_time = min_query_time
        self.details = []
        self.fingerprints = {}
        self.stats = {'total_entries': 0, 'parsed_entries': 0, 'unique_fingerprints': 0, 'date_range': {'start': None, 'end': None}}
        self.debug_mode = False
        
        # ç”¨æˆ·åæ˜ å°„é…ç½®ï¼ˆç›´æ¥å†™åœ¨è„šæœ¬ä¸­ï¼‰
        self.username_mapping = self._get_username_mapping()
        if self.username_mapping:
            print("å·²åŠ è½½ç”¨æˆ·åæ˜ å°„é…ç½®")
        
        # ç”¨æˆ·é»‘åå•é…ç½®ï¼ˆè¿™äº›ç”¨æˆ·çš„æ…¢æŸ¥è¯¢å°†è¢«å¿½ç•¥ï¼‰
        self.username_blacklist = self._get_username_blacklist()
        if self.username_blacklist:
            print(f"å·²åŠ è½½ç”¨æˆ·é»‘åå•é…ç½®: {', '.join(self.username_blacklist)}")

    def _get_username_mapping(self):
        """è·å–ç”¨æˆ·åæ˜ å°„é…ç½®"""
        return {
            # åœ¨è¿™é‡Œç›´æ¥é…ç½®ç”¨æˆ·ååˆ°æ•°æ®åº“çš„æ˜ å°„å…³ç³»
            # æ ¼å¼: 'username': 'database_name'
            'act_user':'posx_act',
            'act_user_prd':'posx_act',
            'aegean_user':'posx_aegean',
            'prd_user':'posx_prd',
            'tras_user':'posx_prd',
            'agentuser':'posx_agent',
            'bss_user':'posx_bss',
            'pms_user':'posx_pms',
            'pps_user':'posx_pps',
            'risk_user':'posx_risk',
            'stock_user':'posx_stock',
            'dc_user':'posx_dc',
            'dls_user':'posx_dlc',
            'dms_user':'posx_dms',
            'drs_user':'posx_drs',
            'ifs_user':'ifs_gateway',
            'ifsedu_user':'ifs_education',
            'k8snacos_user':'wpk8s_nacos',
            'mer_user':'posx_mer',
            'mer_user_prd':'posx_mer',
            'nacos_user':'wpk8s_nacos',
            'rhk_user':'reassure_housekeeper',
            'sas_user':'posx_sas',
            'tcs_user':'posx_tcs',
            'wop_user':'posx_wop',
            'wos_user':'posx_wos',
            'xxl_user':'xxl_job',
            'yeepay_user':'posx_yeepay',
            'dls_o':'posx_dls',
        }

    def _get_username_blacklist(self):
        """è·å–ç”¨æˆ·é»‘åå•é…ç½®"""
        return {
            # åœ¨è¿™é‡Œé…ç½®éœ€è¦å¿½ç•¥çš„ç”¨æˆ·å
            # è¿™äº›ç”¨æˆ·çš„æ…¢æŸ¥è¯¢è®°å½•å°†ä¸ä¼šè¢«è§£æå’Œå­˜å‚¨
            'pmm_user',      # PMMç›‘æ§ç”¨æˆ·
            'root',          # ç³»ç»Ÿç®¡ç†å‘˜
            'mysql',         # MySQLç³»ç»Ÿç”¨æˆ·
            'monitor',       # ç›‘æ§ç”¨æˆ·
            'backup',        # å¤‡ä»½ç”¨æˆ·
            'replication',   # å¤åˆ¶ç”¨æˆ·
            'mysql.sys',     # MySQLç³»ç»Ÿè´¦æˆ·
            'mysql.session', # MySQLä¼šè¯è´¦æˆ·
            'admin',         # é€šç”¨ç®¡ç†å‘˜ï¼ˆå¦‚æœä¸éœ€è¦è®°å½•ï¼‰
            'pt_user',      # å½’æ¡£ç”¨æˆ·
            'archery_user', # archeryuser
            # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šç”¨æˆ·å
        }

    def normalize_sql(self, sql):
        """è§„èŒƒåŒ–SQLè¯­å¥"""
        if not sql or not sql.strip():
            return ""
        
        # åŸºç¡€æ¸…ç†
        normalized = re.sub(r'\s+', ' ', sql.strip())
        
        # å‚æ•°åŒ–å¤„ç†
        patterns = [
            (r"'[^']*'", "'?'"),  # å­—ç¬¦ä¸²å‚æ•°
            (r'"[^"]*"', "'?'"),  # åŒå¼•å·å­—ç¬¦ä¸²
            (r'\b\d+\b', '?'),    # æ•°å­—å‚æ•°
            (r'IN\s*\([^)]+\)', 'IN (?)'),  # INå­å¥
            (r'VALUES\s*\([^)]+\)', 'VALUES (?)'),  # VALUESå­å¥
        ]
        
        for pattern, replacement in patterns:
            normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)
        
        return normalized.upper()

    def generate_checksum(self, normalized_sql):
        """ç”ŸæˆSQLæŒ‡çº¹"""
        return hashlib.md5(normalized_sql.encode('utf-8')).hexdigest()

    def infer_database_from_username(self, username):
        """æ ¹æ®ç”¨æˆ·åæ¨æ–­æ•°æ®åº“å"""
        if username in self.username_mapping:
            return self.username_mapping[username]
        return 'unknown'

    def format_sql(self, sql):
        """æ ¼å¼åŒ–SQLè¯­å¥ - 9æ­¥ä¼˜åŒ–æµç¨‹"""
        if not sql or len(sql.strip()) < 5:
            return sql
            
        try:
            # 1. åŸºç¡€æ¸…ç†
            formatted = sql.strip()
            
            # 2. ç§»é™¤å¤šä½™ç©ºç™½
            formatted = re.sub(r'\s+', ' ', formatted)
            
            # 3. å…³é”®å­—æ¢è¡Œ
            keywords = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'ORDER BY', 'LIMIT', 
                       'INSERT INTO', 'UPDATE', 'DELETE FROM', 'UNION', 'JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'INNER JOIN']
            
            for keyword in keywords:
                formatted = re.sub(f'\\b{keyword}\\b', f'\n{keyword}', formatted, flags=re.IGNORECASE)
            
            # 4. AND/ORæ¢è¡Œ
            formatted = re.sub(r'\b(AND|OR)\b', r'\n\1', formatted, flags=re.IGNORECASE)
            
            # 5. é€—å·åæ¢è¡Œï¼ˆåœ¨SELECTå­å¥ä¸­ï¼‰
            formatted = re.sub(r',(\s*[a-zA-Z_])', r',\n\1', formatted)
            
            # 6. æ¸…ç†å¤šä½™æ¢è¡Œ
            formatted = re.sub(r'\n\s*\n', '\n', formatted)
            formatted = re.sub(r'^\s*\n', '', formatted)
            
            # 7. å…³é”®å­—å¤§å†™
            for keyword in keywords + ['AND', 'OR', 'SET', 'VALUES', 'ON', 'AS', 'IS', 'NULL', 'NOT', 'IN', 'EXISTS']:
                formatted = re.sub(f'\\b{keyword.lower()}\\b', keyword, formatted, flags=re.IGNORECASE)
                formatted = re.sub(f'\\b{keyword.upper()}\\b', keyword, formatted)
            
            # 8. ç¼©è¿›å¤„ç†
            lines = formatted.split('\n')
            indented_lines = []
            for line in lines:
                line = line.strip()
                if line:
                    if any(line.startswith(kw) for kw in ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'ORDER BY', 'LIMIT', 'INSERT', 'UPDATE', 'DELETE']):
                        indented_lines.append(line)
                    else:
                        indented_lines.append('  ' + line)
            
            # 9. æœ€ç»ˆæ•´ç†
            formatted = '\n'.join(indented_lines)
            return formatted.strip()
            
        except Exception as e:
            return sql  # æ ¼å¼åŒ–å¤±è´¥æ—¶è¿”å›åŸSQL

    def parse_slow_log_with_time_range(self, log_file_path, start_time, end_time, use_optimization=True, optimization_threshold=100):
        """ä¸»è§£ææ–¹æ³• - æ”¯æŒæ—¶é—´èŒƒå›´å’Œä¼˜åŒ–"""
        print(f"è§£ææ—¶é—´èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} åˆ° {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ¸…ç©ºä¹‹å‰çš„è§£æç»“æœ
        self.details = []
        self.fingerprints = {}
        self.stats = {'total_entries': 0, 'parsed_entries': 0, 'unique_fingerprints': 0, 'date_range': {'start': None, 'end': None}}
        
        if not os.path.exists(log_file_path):
            raise FileNotFoundError(f"æ…¢æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file_path}")
        
        file_size = os.path.getsize(log_file_path)
        print(f"æ…¢æ—¥å¿—æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.2f} MB")
        
        self._show_log_sample(log_file_path)
        
        # æ ¹æ®æ–‡ä»¶å¤§å°é€‰æ‹©è§£æç­–ç•¥
        if file_size < 50 * 1024 * 1024:  # 50MBä»¥ä¸‹
            print("ä½¿ç”¨æ ‡å‡†è¯»å–æ¨¡å¼...")
        else:
            print("å›é€€åˆ°æ ‡å‡†æ¨¡å¼ï¼Œä½¿ç”¨æµå¼è§£æé¿å…å†…å­˜é—®é¢˜...")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æµå¼è§£ææ–¹æ³•
        self._parse_with_streaming(log_file_path, start_time, end_time)
        
        self.stats['unique_fingerprints'] = len(self.fingerprints)
        print(f"\nè§£æå®Œæˆç»Ÿè®¡:")
        print(f"  æ€»æ—¥å¿—æ¡ç›®: {self.stats['total_entries']}")
        print(f"  æˆåŠŸè§£æ: {self.stats['parsed_entries']}")
        print(f"  å”¯ä¸€SQLæŒ‡çº¹: {self.stats['unique_fingerprints']}")
        print(f"  è¯¦ç»†æ‰§è¡Œè®°å½•: {len(self.details)}")
        if self.stats['date_range']['start']:
            print(f"  æ—¶é—´èŒƒå›´: {self.stats['date_range']['start']} åˆ° {self.stats['date_range']['end']}")
        
        return self.details

    def _parse_with_streaming(self, log_file_path, start_time, end_time):
        """ç»Ÿä¸€çš„æµå¼è§£ææ–¹æ³•"""
        entry_buffer = ""
        entry_count = 0
        processed = 0
        
        print("ä½¿ç”¨æ ‡å‡†æµå¼è§£ææ¨¡å¼...")
        
        with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ¡ç›®çš„å¼€å§‹
                if self._is_entry_start(line):
                    # å¤„ç†å‰ä¸€ä¸ªæ¡ç›®
                    if entry_buffer:
                        if self._parse_single_entry(entry_buffer, start_time, end_time):
                            processed += 1
                    
                    # å¼€å§‹æ–°æ¡ç›®
                    entry_buffer = line
                    entry_count += 1
                    
                    if entry_count % 1000 == 0:
                        print(f"å·²å¤„ç† {entry_count} ä¸ªæ¡ç›®ï¼Œæœ‰æ•ˆè§£æ {processed} ä¸ª...")
                else:
                    entry_buffer += line
            
            # å¤„ç†æœ€åä¸€ä¸ªæ¡ç›®
            if entry_buffer:
                if self._parse_single_entry(entry_buffer, start_time, end_time):
                    processed += 1
        
        self.stats['total_entries'] = entry_count
        self.stats['parsed_entries'] = processed
        print(f"æ ‡å‡†æ¨¡å¼è§£æå®Œæˆï¼Œæ€»æ¡ç›®: {entry_count}ï¼Œæœ‰æ•ˆå¤„ç†: {processed} ä¸ª")

    def _is_entry_start(self, line):
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ¡ç›®å¼€å§‹"""
        return (line.startswith('# Time: ') or 
                bool(re.match(r'^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', line.strip())))

    def _parse_single_entry(self, entry_text, start_time, end_time):
        """è§£æå•ä¸ªæ¡ç›®"""
        lines = entry_text.strip().split('\n')
        if not lines:
            return False
        
        # è§£ææ—¶é—´æˆ³
        timestamp = self._parse_timestamp(lines[0].strip())
        if not timestamp:
            return False
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´
        if timestamp < start_time or timestamp > end_time:
            return False
        
        # æ›´æ–°æ—¶é—´èŒƒå›´ç»Ÿè®¡
        if not self.stats['date_range']['start'] or timestamp < self.stats['date_range']['start']:
            self.stats['date_range']['start'] = timestamp
        if not self.stats['date_range']['end'] or timestamp > self.stats['date_range']['end']:
            self.stats['date_range']['end'] = timestamp
        
        return self._parse_entry_content(lines, timestamp)

    def _parse_timestamp(self, timestamp_line):
        """ç»Ÿä¸€æ—¶é—´æˆ³è§£æ"""
        # ISOæ ¼å¼
        if re.match(r'^\d{4}-\d{2}-\d{2}T', timestamp_line):
            return self._parse_iso_timestamp(timestamp_line)
        
        # ä¼ ç»ŸMySQLæ ¼å¼
        if timestamp_line.startswith('# Time:'):
            return self._extract_timestamp_from_line(timestamp_line)
        
        return None

    def _parse_iso_timestamp(self, timestamp_str):
        """è§£æISOæ—¶é—´æˆ³"""
        formats = [
            '%Y-%m-%dT%H:%M:%S.%f+08:00', '%Y-%m-%dT%H:%M:%S+08:00',
            '%Y-%m-%dT%H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S'
        ]
        
        # ç§»é™¤æ—¶åŒºä¿¡æ¯
        cleaned = timestamp_str.replace('+08:00', '').replace('+0800', '')
        
        for fmt in formats:
            try:
                if '+08:00' in fmt and '+08:00' in timestamp_str:
                    return datetime.strptime(timestamp_str, fmt).replace(tzinfo=None)
                else:
                    return datetime.strptime(cleaned, fmt)
            except ValueError:
                continue
        return None

    def _extract_timestamp_from_line(self, line):
        """è§£æä¼ ç»ŸMySQLæ—¶é—´æˆ³"""
        if not line.startswith('# Time:'):
            return None
        
        timestamp_str = line[7:].strip()
        formats = [
            '%Y-%m-%dT%H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S', '%y%m%d %H:%M:%S',
            '%Y-%m-%d %H:%M:%S', '%Y%m%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f'
        ]
        
        # ç§»é™¤æ—¶åŒº
        timestamp_str = timestamp_str.replace('+08:00', '').replace('+0800', '')
        
        for fmt in formats:
            try:
                timestamp = datetime.strptime(timestamp_str, fmt)
                if timestamp.year < 2024:
                    timestamp = timestamp.replace(year=timestamp.year + 2000)
                return timestamp
            except ValueError:
                continue
        return None

    def _parse_entry_content(self, lines, timestamp):
        """è§£ææ¡ç›®å†…å®¹"""
        # è§£æç”¨æˆ·å’Œæ€§èƒ½æŒ‡æ ‡
        username, dbname = 'unknown', 'unknown'
        query_time = lock_time = rows_sent = rows_examined = 0
        sql_start_idx = -1
        
        for i, line in enumerate(lines[1:], 1):
            if line.startswith('# User@Host:'):
                # æå–ç”¨æˆ·å
                user_match = re.search(r'# User@Host:\s*(\w+)', line)
                if user_match:
                    username = user_match.group(1)
                    
            elif line.startswith('# Query_time:'):
                # è§£ææ€§èƒ½æŒ‡æ ‡
                match = re.search(r'Query_time:\s*([\d.]+)\s*Lock_time:\s*([\d.]+)\s*Rows_sent:\s*(\d+)\s*Rows_examined:\s*(\d+)', line)
                if match:
                    query_time, lock_time = float(match.group(1)), float(match.group(2))
                    rows_sent, rows_examined = int(match.group(3)), int(match.group(4))
                    
            elif not line.startswith('#') and line.strip():
                sql_start_idx = i
                break
        
        if sql_start_idx == -1:
            return False
        
        # æå–SQL
        sql_lines = lines[sql_start_idx:]
        raw_sql = '\n'.join(sql_lines).strip()
        raw_sql = re.sub(r'SET timestamp=\d+;?\s*$', '', raw_sql, flags=re.IGNORECASE).rstrip(';').strip()
        
        # æå–æ•°æ®åº“å
        use_match = re.search(r'USE\s+`?([^`\s;]+)`?\s*;?', raw_sql, re.IGNORECASE)
        if use_match:
            dbname = use_match.group(1)
            raw_sql = re.sub(r'USE\s+`?\w+`?\s*;\s*', '', raw_sql, flags=re.IGNORECASE).strip()
        elif username != 'unknown':
            dbname = self.infer_database_from_username(username)
        
        # è¿‡æ»¤æ¡ä»¶
        if (not raw_sql or len(raw_sql) < 10 or 
            query_time < self.min_query_time or 
            'index not used' in raw_sql.lower() or
            username in self.username_blacklist):  # ç”¨æˆ·é»‘åå•è¿‡æ»¤
            
            # è®°å½•è¢«è¿‡æ»¤çš„åŸå› ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
            if self.debug_mode and username in self.username_blacklist:
                print(f"âš« è¿‡æ»¤é»‘åå•ç”¨æˆ·: {username}")
            
            return False
        
        # ç”ŸæˆæŒ‡çº¹
        normalized_sql = self.normalize_sql(raw_sql)
        checksum = self.generate_checksum(normalized_sql)
        
        # å­˜å‚¨æŒ‡çº¹
        if checksum not in self.fingerprints:
            self.fingerprints[checksum] = {
                'checksum': checksum, 'normalized_sql': normalized_sql,
                'raw_sql': raw_sql, 'username': username, 'dbname': dbname,
                'first_seen': timestamp, 'last_seen': timestamp,
                'reviewed_status': 'å¾…ä¼˜åŒ–', 'comments': None
            }
        else:
            fp = self.fingerprints[checksum]
            fp['last_seen'] = max(fp['last_seen'], timestamp)
            fp['first_seen'] = min(fp['first_seen'], timestamp)
        
        # å­˜å‚¨è¯¦ç»†è®°å½•
        self.details.append({
            'checksum': checksum, 'sql_text': raw_sql,
            'formatted_sql': self.format_sql(raw_sql), 'timestamp': timestamp,
            'query_time': query_time, 'lock_time': lock_time,
            'rows_sent': rows_sent, 'rows_examined': rows_examined,
            'username': username, 'dbname': dbname
        })
        
        return True

    def _show_log_sample(self, log_file_path):
        """æ˜¾ç¤ºæ—¥å¿—æ ·æœ¬"""
        print("\n=== æ—¥å¿—æ–‡ä»¶æ ·æœ¬ ===")
        try:
            with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                print(f.read(2000))
            print("=== æ ·æœ¬ç»“æŸ ===\n")
        except Exception as e:
            print(f"è¯»å–æ ·æœ¬å¤±è´¥: {e}")

    def save_to_database(self):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        if not self.fingerprints:
            print("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        try:
            # è¿æ¥æ•°æ®åº“
            connection = pymysql.connect(
                host='172.16.176.70', user='root', password='SlowQ#123',
                database='slow_query_analysis', charset='utf8mb4'
            )
            
            with connection.cursor() as cursor:
                # ä¿å­˜æŒ‡çº¹æ•°æ®ï¼ˆä½¿ç”¨åŸæ¥çš„è¡¨åå’Œç»“æ„ï¼‰
                for fp in self.fingerprints.values():
                    cursor.execute("""
                        INSERT INTO slow_query_fingerprint (checksum, normalized_sql, raw_sql, username, dbname, 
                                                           first_seen, last_seen, reviewed_status, comments)
                        VALUES (%(checksum)s, %(normalized_sql)s, %(raw_sql)s, %(username)s, %(dbname)s,
                               %(first_seen)s, %(last_seen)s, %(reviewed_status)s, %(comments)s)
                        ON DUPLICATE KEY UPDATE
                        first_seen = LEAST(first_seen, VALUES(first_seen)),
                        last_seen = GREATEST(last_seen, VALUES(last_seen)),
                        raw_sql = VALUES(raw_sql)
                    """, fp)
                
                # ä¿å­˜è¯¦ç»†è®°å½•ï¼ˆä½¿ç”¨åŸæ¥çš„è¡¨åå’Œç»“æ„ï¼‰
                for detail in self.details:
                    cursor.execute("""
                        INSERT IGNORE INTO slow_query_detail (checksum, sql_text, timestamp, 
                                                             query_time, lock_time, rows_sent, rows_examined)
                        VALUES (%(checksum)s, %(formatted_sql)s, %(timestamp)s,
                               %(query_time)s, %(lock_time)s, %(rows_sent)s, %(rows_examined)s)
                    """, detail)
                
                connection.commit()
                print(f"\næ•°æ®ä¿å­˜æˆåŠŸ:")
                print(f"  SQLæŒ‡çº¹è®°å½•: {len(self.fingerprints)} æ¡")
                print(f"  è¯¦ç»†æ‰§è¡Œè®°å½•: {len(self.details)} æ¡")
                
        except Exception as e:
            print(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        finally:
            if 'connection' in locals():
                connection.close()

def _parse_time_range(args):
    """è§£ææ—¶é—´èŒƒå›´å‚æ•°"""
    try:
        # ä¼˜å…ˆä½¿ç”¨ç²¾ç¡®çš„æ—¶é—´èŒƒå›´
        if args.start_time and args.end_time:
            start_time = datetime.strptime(args.start_time, '%Y-%m-%d %H:%M:%S')
            end_time = datetime.strptime(args.end_time, '%Y-%m-%d %H:%M:%S')
            print(f"ä½¿ç”¨è‡ªå®šä¹‰æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
            return start_time, end_time
        
        # ä½¿ç”¨æ—¥æœŸèŒƒå›´ï¼ˆå¦‚æœåªæŒ‡å®šäº†æ—¥æœŸï¼‰
        elif args.start_date or args.end_date:
            if args.start_date:
                start_time = datetime.strptime(args.start_date + ' 00:00:00', '%Y-%m-%d %H:%M:%S')
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šå¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä»ä¸€å‘¨å‰å¼€å§‹
                start_time = datetime.now() - timedelta(days=7)
            
            if args.end_date:
                end_time = datetime.strptime(args.end_date + ' 23:59:59', '%Y-%m-%d %H:%M:%S')
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šç»“æŸæ—¥æœŸï¼Œé»˜è®¤åˆ°å½“å‰æ—¶é—´
                end_time = datetime.now()
            
            print(f"ä½¿ç”¨è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} åˆ° {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            return start_time, end_time
        
        # ä½¿ç”¨å•ç‹¬çš„å¼€å§‹æ—¶é—´æˆ–ç»“æŸæ—¶é—´
        elif args.start_time:
            start_time = datetime.strptime(args.start_time, '%Y-%m-%d %H:%M:%S')
            end_time = datetime.now()
            print(f"ä»æŒ‡å®šæ—¶é—´åˆ°ç°åœ¨: {start_time} åˆ° {end_time}")
            return start_time, end_time
        
        elif args.end_time:
            end_time = datetime.strptime(args.end_time, '%Y-%m-%d %H:%M:%S')
            start_time = end_time - timedelta(days=args.days)
            print(f"ä»{args.days}å¤©å‰åˆ°æŒ‡å®šæ—¶é—´: {start_time} åˆ° {end_time}")
            return start_time, end_time
        
        # é»˜è®¤ä½¿ç”¨dayså‚æ•°
        else:
            end_time = datetime.now()
            start_time = end_time - timedelta(days=args.days)
            print(f"ä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´: æœ€è¿‘{args.days}å¤©")
            return start_time, end_time
            
    except ValueError as e:
        print(f"âŒ æ—¶é—´æ ¼å¼é”™è¯¯: {e}")
        print("è¯·ä½¿ç”¨æ ¼å¼: YYYY-MM-DD HH:MM:SS (å¦‚: 2025-09-12 10:30:00)")
        print("æˆ–ä½¿ç”¨æ—¥æœŸæ ¼å¼: YYYY-MM-DD (å¦‚: 2025-09-12)")
        exit(1)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MySQLæ…¢æŸ¥è¯¢æ—¥å¿—è§£æå™¨')
    parser.add_argument('--log-file', default='/data/mysql/log/slow.log', help='æ…¢æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--days', type=int, default=7, help='è§£ææœ€è¿‘Nå¤©çš„æ—¥å¿—')
    parser.add_argument('--min-time', type=float, default=5.0, help='æœ€å°æŸ¥è¯¢æ—¶é—´é˜ˆå€¼(ç§’)')
    parser.add_argument('--save-db', action='store_true', help='ä¿å­˜åˆ°æ•°æ®åº“')
    
    # è‡ªå®šä¹‰æ—¶é—´èŒƒå›´å‚æ•°
    parser.add_argument('--start-time', type=str, help='å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)')
    parser.add_argument('--end-time', type=str, help='ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)')
    parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œæ—¶é—´é»˜è®¤00:00:00)')
    parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œæ—¶é—´é»˜è®¤23:59:59)')
    
    # ç”¨æˆ·è¿‡æ»¤å‚æ•°
    parser.add_argument('--disable-blacklist', action='store_true', help='ç¦ç”¨ç”¨æˆ·é»‘åå•è¿‡æ»¤')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¿‡æ»¤è¯¦æƒ…')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè§£æå™¨
    slow_parser = SlowLogParser(min_query_time=args.min_time)
    
    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    if args.debug:
        slow_parser.debug_mode = True
        print("ğŸ” è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
    
    # å¤„ç†é»‘åå•è®¾ç½®
    if args.disable_blacklist:
        slow_parser.username_blacklist = set()  # æ¸…ç©ºé»‘åå•
        print("âšª ç”¨æˆ·é»‘åå•å·²ç¦ç”¨")
    
    # è§£æè‡ªå®šä¹‰æ—¶é—´èŒƒå›´
    start_time, end_time = _parse_time_range(args)
    
    try:
        # è§£ææ—¥å¿—
        print(f"å¼€å§‹è§£ææ…¢æŸ¥è¯¢æ—¥å¿—: {args.log_file}")
        print(f"æŸ¥è¯¢æ—¶é—´é˜ˆå€¼: {args.min_time}ç§’")
        
        results = slow_parser.parse_slow_log_with_time_range(args.log_file, start_time, end_time)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if args.save_db:
            slow_parser.save_to_database()
        
        print("\nâœ… è§£æå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
